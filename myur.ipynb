{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def init(self, matrix, n, activation='relu'): # 1x786\n",
    "        self.weights = np.random.rand(matrix.shape[1], n)  # 786x16\n",
    "        self.bias = np.random.rand(1, n)  #1x16\n",
    "        self.activation = activation\n",
    "\n",
    "    def apply_activation(self, values):\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0, values)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-values))\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(values)\n",
    "        else:\n",
    "            return values  # No activation (identity)\n",
    "\n",
    "    def get_values(self,matrix):\n",
    "        next_neuron_vals = np.dot(matrix, self.weights) + self.bias \n",
    "        return self.apply_activation(next_neuron_vals)\n",
    "\n",
    "\n",
    "def flat(matrix):\n",
    "  return matrix.flatten()\n",
    "\n",
    "input_matrix = flat(img)\n",
    "hiddenLayer_1 = (input_matrix, 16)\n",
    "hiddenLayer_2 = (hiddenLayer_1, 16)\n",
    "output_layer = (hiddenLayer_2, 10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
